{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0j65zA8kG7tB"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1609154969126,
     "user": {
      "displayName": "Matt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIzeuHHD36c1-IgguXB5KjqEoCp7UsZBNQGGvx5Q=s64",
      "userId": "13529861564108685423"
     },
     "user_tz": -540
    },
    "id": "wGZq_nDiG7tJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from percolation import read_percolation_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "import metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoderConv2D_1(input_shape=(256, 256, 1), filters=[32, 64, 128, 10]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "\n",
    "    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n",
    "\n",
    "    x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(encoded)\n",
    "\n",
    "    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n",
    "    x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1')(x)\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = autoencoderConv2D_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 128, 128, 32)      832       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 64, 64, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 10)                1310730   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 131072)            1441792   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "deconv3 (Conv2DTranspose)    (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)    (None, 128, 128, 32)      51232     \n",
      "_________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)    (None, 256, 256, 1)       801       \n",
      "=================================================================\n",
      "Total params: 3,004,299\n",
      "Trainable params: 3,004,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 256\n",
    "pc = 0.59274\n",
    "#p_arr = np.round(np.arange(0, 1.0, 0.01), 4)\n",
    "p_arr = np.round(np.array([0.57, 0.58, 0.61, 0.62]), 4)\n",
    "p_arr = np.append(p_arr, pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = read_percolation_data(L, p_arr, pc, max_configs_per_p=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 256, 256, 1) (500,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x.shape[0]\n",
    "L = x.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (500, 256, 256, 1) , y.shape: (500,)\n",
      "X_train.shape: (400, 256, 256, 1) , y_train.shape: (400,)\n",
      "X_test.shape: (100, 256, 256, 1) , y_test.shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "print('X.shape:', x.shape, ', y.shape:', y.shape)\n",
    "print('X_train.shape:', x_train.shape, ', y_train.shape:', y_train.shape)\n",
    "print('X_test.shape:', x_test.shape, ', y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 754,
     "status": "ok",
     "timestamp": 1609154986398,
     "user": {
      "displayName": "Matt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIzeuHHD36c1-IgguXB5KjqEoCp7UsZBNQGGvx5Q=s64",
      "userId": "13529861564108685423"
     },
     "user_tz": -540
    },
    "id": "W5bbJ6lDG7tL",
    "outputId": "d1ef6d1b-782c-43fe-ce3e-53986a3301d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "K = len(set(y_train))\n",
    "print(\"number of classes:\", K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the convolutional auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/Users/matthieu.sarkis/git_repos/criticality_trained_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x, x, batch_size=batch_size, epochs=pretrain_epochs)\n",
    "autoencoder.save_weights(save_dir+'conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(save_dir+'conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "         Measure the similarity between embedded point z_i and centroid µ_j.\n",
    "                 q_ij = 1/(1+dist(x_i, µ_j)^2), then normalize it.\n",
    "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "                 (i.e., a soft assignment)\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
